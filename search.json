[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "autobackup",
    "section": "",
    "text": "Install latest from the GitHub repository:\n$ pip install git+https://github.com/johnowhitaker/autobackup.git\nor from pypi\n$ pip install autobackup",
    "crumbs": [
      "autobackup"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "autobackup",
    "section": "",
    "text": "Install latest from the GitHub repository:\n$ pip install git+https://github.com/johnowhitaker/autobackup.git\nor from pypi\n$ pip install autobackup",
    "crumbs": [
      "autobackup"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "autobackup",
    "section": "How to use",
    "text": "How to use\nautobackup src dest will make a copy of src (which can be a file or a directory) inside dir in a folder with the current date+time, and clean up any old backups based on the following rules:\n\nThe most recent 5 backups are kept\nFor each number of days in --max_ages (default is “2,14,60”) the oldest one below that age is kept.\n\nThis ensures that you have a few recent backups, one up to 2 days old, one up to 2 weeks old and one up to 2 months old.\nTo run this script hourly,\n\nCreate a service file (e.g. /etc/systemd/system/backup.service):\n\n[Unit]\nDescription=Hourly Backup Service\n\n[Service]\nExecStart=autobackup /path/to/src /path/to/dest\n\n[Install]\nWantedBy=multi-user.target\n\nCreate a timer file (e.g. /etc/systemd/system/backup.timer):\n\n[Unit]\nDescription=Run Backup Service Hourly\n\n[Timer]\nOnCalendar=hourly\n\n[Install]\nWantedBy=timers.target\n\nEnable and start the timer:\n\nsudo systemctl enable backup.timer\nsudo systemctl start backup.timer",
    "crumbs": [
      "autobackup"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "We want a script to back up a specific file/folder over different intervals. Specifically, it should\n\nCopy to some destination dir every hour (e.g. a different drive)\nKeep the last 5, and one every day, week and month (for example)\n\nWe can then rsync the destination dir to keep a remote backup.\n\n!mkdir -p demo_src\n!mkdir -p demo_dst\n!rm -r demo_dst/*\n\n\n!echo \"content\" &gt; \"demo_src/$(date +%s).txt\"\n\n\n\nThe plan has two main steps:\n\nCreate a new backup\nClean up any old backups that are no longer needed.\n\nStep 1 is easy enough:\n\nsource\n\n\n\n create_backup (src, dest_dir)\n\n\ncreate_backup('demo_src', 'demo_dst')\n!ls demo_dst\n\n20241115_120316\n\n\nThe harder part is the cleanup. Let’s start by generating some dates to test with.\n\ndef generate_test_dates(num_dates, base_date):\n    return [(base_date + timedelta(hours=i)).strftime(\"%Y%m%d_%H%M%S\") for i in range(num_dates)]\ntest_dates = generate_test_dates(2400, datetime.now() - timedelta(days=100))\nprint(test_dates[:5], test_dates[-5:])\n\n['20240807_120317', '20240807_130317', '20240807_140317', '20240807_150317', '20240807_160317'] ['20241115_070317', '20241115_080317', '20241115_090317', '20241115_100317', '20241115_110317']\n\n\n\n# Can I get all dates &lt; 2 months old?\n[d for d in test_dates if (datetime.now() - datetime.strptime(d, '%Y%m%d_%H%M%S')).days &lt; 60][:3]\n\n['20240916_130317', '20240916_140317', '20240916_150317']\n\n\nNow we want to grab the most recent 5, and then the oldest below some threshold.\n\nsource\n\n\n\n\n clean_dates (dates, now=None, max_ages=(2, 14, 60))\n\n\nclean_dates(test_dates)\n\n['20240916_130317',\n '20241101_130317',\n '20241113_130317',\n '20241115_070317',\n '20241115_080317',\n '20241115_090317',\n '20241115_100317',\n '20241115_110317']\n\n\nNow we want code that starts with the same test dates etc as above, but then simulates time passing by adding an hour to ‘now’ and a date to test dates every step then printing out a (prettified) version of clean_dates to check it’s doing as I expect over a simulated month.\n\n# Initialize\nnow = datetime.now()\ntest_dates = generate_test_dates(2400, now - timedelta(days=100))\n\n# Simulate time passing\nfor _ in range(30 * 24):  # Simulate a month (30 days * 24 hours)\n    now += timedelta(hours=1)\n    test_dates.append(now.strftime(\"%Y%m%d_%H%M%S\"))\n    test_dates = clean_dates(test_dates, now)  # Clean up old dates\n    if _ % 24 == 0:  # Print once a day\n        print(f\"\\nDay {_ // 24 + 1}:\")\n        pprint.pprint(test_dates)\n\n\nDay 1:\n['20240916_140322',\n '20241101_140322',\n '20241113_140322',\n '20241115_080322',\n '20241115_090322',\n '20241115_100322',\n '20241115_110322',\n '20241115_130322']\n\nDay 2:\n['20241101_140322',\n '20241113_140322',\n '20241115_080322',\n '20241116_090322',\n '20241116_100322',\n '20241116_110322',\n '20241116_120322',\n '20241116_130322']\n\nDay 3:\n['20241101_140322',\n '20241113_140322',\n '20241117_030322',\n '20241117_090322',\n '20241117_100322',\n '20241117_110322',\n '20241117_120322',\n '20241117_130322']\n\nDay 4:\n['20241101_140322',\n '20241113_140322',\n '20241117_030322',\n '20241118_090322',\n '20241118_100322',\n '20241118_110322',\n '20241118_120322',\n '20241118_130322']\n\nDay 5:\n['20241101_140322',\n '20241113_140322',\n '20241118_220322',\n '20241119_090322',\n '20241119_100322',\n '20241119_110322',\n '20241119_120322',\n '20241119_130322']\n\nDay 6:\n['20241101_140322',\n '20241113_140322',\n '20241118_220322',\n '20241120_090322',\n '20241120_100322',\n '20241120_110322',\n '20241120_120322',\n '20241120_130322']\n\nDay 7:\n['20241101_140322',\n '20241113_140322',\n '20241120_170322',\n '20241121_090322',\n '20241121_100322',\n '20241121_110322',\n '20241121_120322',\n '20241121_130322']\n\nDay 8:\n['20241101_140322',\n '20241113_140322',\n '20241120_170322',\n '20241122_090322',\n '20241122_100322',\n '20241122_110322',\n '20241122_120322',\n '20241122_130322']\n\nDay 9:\n['20241101_140322',\n '20241113_140322',\n '20241122_120322',\n '20241123_090322',\n '20241123_100322',\n '20241123_110322',\n '20241123_120322',\n '20241123_130322']\n\nDay 10:\n['20241101_140322',\n '20241113_140322',\n '20241124_070322',\n '20241124_090322',\n '20241124_100322',\n '20241124_110322',\n '20241124_120322',\n '20241124_130322']\n\nDay 11:\n['20241101_140322',\n '20241113_140322',\n '20241124_070322',\n '20241125_090322',\n '20241125_100322',\n '20241125_110322',\n '20241125_120322',\n '20241125_130322']\n\nDay 12:\n['20241101_140322',\n '20241113_140322',\n '20241126_020322',\n '20241126_090322',\n '20241126_100322',\n '20241126_110322',\n '20241126_120322',\n '20241126_130322']\n\nDay 13:\n['20241101_140322',\n '20241113_140322',\n '20241126_020322',\n '20241127_090322',\n '20241127_100322',\n '20241127_110322',\n '20241127_120322',\n '20241127_130322']\n\nDay 14:\n['20241101_140322',\n '20241126_020322',\n '20241127_210322',\n '20241128_090322',\n '20241128_100322',\n '20241128_110322',\n '20241128_120322',\n '20241128_130322']\n\nDay 15:\n['20241101_140322',\n '20241126_020322',\n '20241127_210322',\n '20241129_090322',\n '20241129_100322',\n '20241129_110322',\n '20241129_120322',\n '20241129_130322']\n\nDay 16:\n['20241101_140322',\n '20241126_020322',\n '20241129_160322',\n '20241130_090322',\n '20241130_100322',\n '20241130_110322',\n '20241130_120322',\n '20241130_130322']\n\nDay 17:\n['20241101_140322',\n '20241126_020322',\n '20241129_160322',\n '20241201_090322',\n '20241201_100322',\n '20241201_110322',\n '20241201_120322',\n '20241201_130322']\n\nDay 18:\n['20241101_140322',\n '20241126_020322',\n '20241201_110322',\n '20241202_090322',\n '20241202_100322',\n '20241202_110322',\n '20241202_120322',\n '20241202_130322']\n\nDay 19:\n['20241101_140322',\n '20241126_020322',\n '20241203_060322',\n '20241203_090322',\n '20241203_100322',\n '20241203_110322',\n '20241203_120322',\n '20241203_130322']\n\nDay 20:\n['20241101_140322',\n '20241126_020322',\n '20241203_060322',\n '20241204_090322',\n '20241204_100322',\n '20241204_110322',\n '20241204_120322',\n '20241204_130322']\n\nDay 21:\n['20241101_140322',\n '20241126_020322',\n '20241205_010322',\n '20241205_090322',\n '20241205_100322',\n '20241205_110322',\n '20241205_120322',\n '20241205_130322']\n\nDay 22:\n['20241101_140322',\n '20241126_020322',\n '20241205_010322',\n '20241206_090322',\n '20241206_100322',\n '20241206_110322',\n '20241206_120322',\n '20241206_130322']\n\nDay 23:\n['20241101_140322',\n '20241126_020322',\n '20241206_200322',\n '20241207_090322',\n '20241207_100322',\n '20241207_110322',\n '20241207_120322',\n '20241207_130322']\n\nDay 24:\n['20241101_140322',\n '20241126_020322',\n '20241206_200322',\n '20241208_090322',\n '20241208_100322',\n '20241208_110322',\n '20241208_120322',\n '20241208_130322']\n\nDay 25:\n['20241101_140322',\n '20241126_020322',\n '20241208_150322',\n '20241209_090322',\n '20241209_100322',\n '20241209_110322',\n '20241209_120322',\n '20241209_130322']\n\nDay 26:\n['20241101_140322',\n '20241208_150322',\n '20241210_090322',\n '20241210_100322',\n '20241210_110322',\n '20241210_120322',\n '20241210_130322']\n\nDay 27:\n['20241101_140322',\n '20241208_150322',\n '20241210_100322',\n '20241211_090322',\n '20241211_100322',\n '20241211_110322',\n '20241211_120322',\n '20241211_130322']\n\nDay 28:\n['20241101_140322',\n '20241208_150322',\n '20241212_050322',\n '20241212_090322',\n '20241212_100322',\n '20241212_110322',\n '20241212_120322',\n '20241212_130322']\n\nDay 29:\n['20241101_140322',\n '20241208_150322',\n '20241212_050322',\n '20241213_090322',\n '20241213_100322',\n '20241213_110322',\n '20241213_120322',\n '20241213_130322']\n\nDay 30:\n['20241101_140322',\n '20241208_150322',\n '20241214_000322',\n '20241214_090322',\n '20241214_100322',\n '20241214_110322',\n '20241214_120322',\n '20241214_130322']\n\n\nNB: Yay, it looks to be doing mostly what I want! I can collapse the output, if you’re viewing this in a notebook my apologies :)\n\n\n\n\nNow that those two pieces of functionality seem to be working, we can wrap this up as a script using fastcore’s call_parse, have it run the backup, clean up old files, and log any errors or messages to backup.log\n\nsource\n\n\n\n run_backup (src:str, dest:str, max_ages:str='2,14,60',\n             log_file:str='backup.log')\n\nRun backup and cleanup old files\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsrc\nstr\n\nThe source to be backed up\n\n\ndest\nstr\n\nThe destination directory\n\n\nmax_ages\nstr\n2,14,60\nThe max age(s) in days for the different backups\n\n\nlog_file\nstr\nbackup.log\n\n\n\n\n\n!ls demo_src\n\n1731699240.txt  1731700528.txt  1731700920.txt\n1731700503.txt  1731700856.txt  1731700993.txt\n\n\nTesting a directory:\n\n!rm -r demo_dst/*\n\n\nrun_backup('demo_src', 'demo_dst',)\n!ls demo_dst\n\n20241115_120331\n\n\n\n!ls demo_dst/20241115_120331\n\n1731699240.txt  1731700528.txt  1731700920.txt\n1731700503.txt  1731700856.txt  1731700993.txt\n\n\nTesting a single file\n\n!rm -r demo_dst/*\n\n\nrun_backup('demo_src/1731700503.txt', 'demo_dst')\n\n\n!ls demo_dst\n\n20241115_120341\n\n\n\n!ls demo_dst/20241115_120341\n\n1731700503.txt",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#the-core-functionality",
    "href": "core.html#the-core-functionality",
    "title": "core",
    "section": "",
    "text": "The plan has two main steps:\n\nCreate a new backup\nClean up any old backups that are no longer needed.\n\nStep 1 is easy enough:\n\nsource\n\n\n\n create_backup (src, dest_dir)\n\n\ncreate_backup('demo_src', 'demo_dst')\n!ls demo_dst\n\n20241115_120316\n\n\nThe harder part is the cleanup. Let’s start by generating some dates to test with.\n\ndef generate_test_dates(num_dates, base_date):\n    return [(base_date + timedelta(hours=i)).strftime(\"%Y%m%d_%H%M%S\") for i in range(num_dates)]\ntest_dates = generate_test_dates(2400, datetime.now() - timedelta(days=100))\nprint(test_dates[:5], test_dates[-5:])\n\n['20240807_120317', '20240807_130317', '20240807_140317', '20240807_150317', '20240807_160317'] ['20241115_070317', '20241115_080317', '20241115_090317', '20241115_100317', '20241115_110317']\n\n\n\n# Can I get all dates &lt; 2 months old?\n[d for d in test_dates if (datetime.now() - datetime.strptime(d, '%Y%m%d_%H%M%S')).days &lt; 60][:3]\n\n['20240916_130317', '20240916_140317', '20240916_150317']\n\n\nNow we want to grab the most recent 5, and then the oldest below some threshold.\n\nsource\n\n\n\n\n clean_dates (dates, now=None, max_ages=(2, 14, 60))\n\n\nclean_dates(test_dates)\n\n['20240916_130317',\n '20241101_130317',\n '20241113_130317',\n '20241115_070317',\n '20241115_080317',\n '20241115_090317',\n '20241115_100317',\n '20241115_110317']\n\n\nNow we want code that starts with the same test dates etc as above, but then simulates time passing by adding an hour to ‘now’ and a date to test dates every step then printing out a (prettified) version of clean_dates to check it’s doing as I expect over a simulated month.\n\n# Initialize\nnow = datetime.now()\ntest_dates = generate_test_dates(2400, now - timedelta(days=100))\n\n# Simulate time passing\nfor _ in range(30 * 24):  # Simulate a month (30 days * 24 hours)\n    now += timedelta(hours=1)\n    test_dates.append(now.strftime(\"%Y%m%d_%H%M%S\"))\n    test_dates = clean_dates(test_dates, now)  # Clean up old dates\n    if _ % 24 == 0:  # Print once a day\n        print(f\"\\nDay {_ // 24 + 1}:\")\n        pprint.pprint(test_dates)\n\n\nDay 1:\n['20240916_140322',\n '20241101_140322',\n '20241113_140322',\n '20241115_080322',\n '20241115_090322',\n '20241115_100322',\n '20241115_110322',\n '20241115_130322']\n\nDay 2:\n['20241101_140322',\n '20241113_140322',\n '20241115_080322',\n '20241116_090322',\n '20241116_100322',\n '20241116_110322',\n '20241116_120322',\n '20241116_130322']\n\nDay 3:\n['20241101_140322',\n '20241113_140322',\n '20241117_030322',\n '20241117_090322',\n '20241117_100322',\n '20241117_110322',\n '20241117_120322',\n '20241117_130322']\n\nDay 4:\n['20241101_140322',\n '20241113_140322',\n '20241117_030322',\n '20241118_090322',\n '20241118_100322',\n '20241118_110322',\n '20241118_120322',\n '20241118_130322']\n\nDay 5:\n['20241101_140322',\n '20241113_140322',\n '20241118_220322',\n '20241119_090322',\n '20241119_100322',\n '20241119_110322',\n '20241119_120322',\n '20241119_130322']\n\nDay 6:\n['20241101_140322',\n '20241113_140322',\n '20241118_220322',\n '20241120_090322',\n '20241120_100322',\n '20241120_110322',\n '20241120_120322',\n '20241120_130322']\n\nDay 7:\n['20241101_140322',\n '20241113_140322',\n '20241120_170322',\n '20241121_090322',\n '20241121_100322',\n '20241121_110322',\n '20241121_120322',\n '20241121_130322']\n\nDay 8:\n['20241101_140322',\n '20241113_140322',\n '20241120_170322',\n '20241122_090322',\n '20241122_100322',\n '20241122_110322',\n '20241122_120322',\n '20241122_130322']\n\nDay 9:\n['20241101_140322',\n '20241113_140322',\n '20241122_120322',\n '20241123_090322',\n '20241123_100322',\n '20241123_110322',\n '20241123_120322',\n '20241123_130322']\n\nDay 10:\n['20241101_140322',\n '20241113_140322',\n '20241124_070322',\n '20241124_090322',\n '20241124_100322',\n '20241124_110322',\n '20241124_120322',\n '20241124_130322']\n\nDay 11:\n['20241101_140322',\n '20241113_140322',\n '20241124_070322',\n '20241125_090322',\n '20241125_100322',\n '20241125_110322',\n '20241125_120322',\n '20241125_130322']\n\nDay 12:\n['20241101_140322',\n '20241113_140322',\n '20241126_020322',\n '20241126_090322',\n '20241126_100322',\n '20241126_110322',\n '20241126_120322',\n '20241126_130322']\n\nDay 13:\n['20241101_140322',\n '20241113_140322',\n '20241126_020322',\n '20241127_090322',\n '20241127_100322',\n '20241127_110322',\n '20241127_120322',\n '20241127_130322']\n\nDay 14:\n['20241101_140322',\n '20241126_020322',\n '20241127_210322',\n '20241128_090322',\n '20241128_100322',\n '20241128_110322',\n '20241128_120322',\n '20241128_130322']\n\nDay 15:\n['20241101_140322',\n '20241126_020322',\n '20241127_210322',\n '20241129_090322',\n '20241129_100322',\n '20241129_110322',\n '20241129_120322',\n '20241129_130322']\n\nDay 16:\n['20241101_140322',\n '20241126_020322',\n '20241129_160322',\n '20241130_090322',\n '20241130_100322',\n '20241130_110322',\n '20241130_120322',\n '20241130_130322']\n\nDay 17:\n['20241101_140322',\n '20241126_020322',\n '20241129_160322',\n '20241201_090322',\n '20241201_100322',\n '20241201_110322',\n '20241201_120322',\n '20241201_130322']\n\nDay 18:\n['20241101_140322',\n '20241126_020322',\n '20241201_110322',\n '20241202_090322',\n '20241202_100322',\n '20241202_110322',\n '20241202_120322',\n '20241202_130322']\n\nDay 19:\n['20241101_140322',\n '20241126_020322',\n '20241203_060322',\n '20241203_090322',\n '20241203_100322',\n '20241203_110322',\n '20241203_120322',\n '20241203_130322']\n\nDay 20:\n['20241101_140322',\n '20241126_020322',\n '20241203_060322',\n '20241204_090322',\n '20241204_100322',\n '20241204_110322',\n '20241204_120322',\n '20241204_130322']\n\nDay 21:\n['20241101_140322',\n '20241126_020322',\n '20241205_010322',\n '20241205_090322',\n '20241205_100322',\n '20241205_110322',\n '20241205_120322',\n '20241205_130322']\n\nDay 22:\n['20241101_140322',\n '20241126_020322',\n '20241205_010322',\n '20241206_090322',\n '20241206_100322',\n '20241206_110322',\n '20241206_120322',\n '20241206_130322']\n\nDay 23:\n['20241101_140322',\n '20241126_020322',\n '20241206_200322',\n '20241207_090322',\n '20241207_100322',\n '20241207_110322',\n '20241207_120322',\n '20241207_130322']\n\nDay 24:\n['20241101_140322',\n '20241126_020322',\n '20241206_200322',\n '20241208_090322',\n '20241208_100322',\n '20241208_110322',\n '20241208_120322',\n '20241208_130322']\n\nDay 25:\n['20241101_140322',\n '20241126_020322',\n '20241208_150322',\n '20241209_090322',\n '20241209_100322',\n '20241209_110322',\n '20241209_120322',\n '20241209_130322']\n\nDay 26:\n['20241101_140322',\n '20241208_150322',\n '20241210_090322',\n '20241210_100322',\n '20241210_110322',\n '20241210_120322',\n '20241210_130322']\n\nDay 27:\n['20241101_140322',\n '20241208_150322',\n '20241210_100322',\n '20241211_090322',\n '20241211_100322',\n '20241211_110322',\n '20241211_120322',\n '20241211_130322']\n\nDay 28:\n['20241101_140322',\n '20241208_150322',\n '20241212_050322',\n '20241212_090322',\n '20241212_100322',\n '20241212_110322',\n '20241212_120322',\n '20241212_130322']\n\nDay 29:\n['20241101_140322',\n '20241208_150322',\n '20241212_050322',\n '20241213_090322',\n '20241213_100322',\n '20241213_110322',\n '20241213_120322',\n '20241213_130322']\n\nDay 30:\n['20241101_140322',\n '20241208_150322',\n '20241214_000322',\n '20241214_090322',\n '20241214_100322',\n '20241214_110322',\n '20241214_120322',\n '20241214_130322']\n\n\nNB: Yay, it looks to be doing mostly what I want! I can collapse the output, if you’re viewing this in a notebook my apologies :)",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#turning-it-into-a-script",
    "href": "core.html#turning-it-into-a-script",
    "title": "core",
    "section": "",
    "text": "Now that those two pieces of functionality seem to be working, we can wrap this up as a script using fastcore’s call_parse, have it run the backup, clean up old files, and log any errors or messages to backup.log\n\nsource\n\n\n\n run_backup (src:str, dest:str, max_ages:str='2,14,60',\n             log_file:str='backup.log')\n\nRun backup and cleanup old files\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsrc\nstr\n\nThe source to be backed up\n\n\ndest\nstr\n\nThe destination directory\n\n\nmax_ages\nstr\n2,14,60\nThe max age(s) in days for the different backups\n\n\nlog_file\nstr\nbackup.log\n\n\n\n\n\n!ls demo_src\n\n1731699240.txt  1731700528.txt  1731700920.txt\n1731700503.txt  1731700856.txt  1731700993.txt\n\n\nTesting a directory:\n\n!rm -r demo_dst/*\n\n\nrun_backup('demo_src', 'demo_dst',)\n!ls demo_dst\n\n20241115_120331\n\n\n\n!ls demo_dst/20241115_120331\n\n1731699240.txt  1731700528.txt  1731700920.txt\n1731700503.txt  1731700856.txt  1731700993.txt\n\n\nTesting a single file\n\n!rm -r demo_dst/*\n\n\nrun_backup('demo_src/1731700503.txt', 'demo_dst')\n\n\n!ls demo_dst\n\n20241115_120341\n\n\n\n!ls demo_dst/20241115_120341\n\n1731700503.txt",
    "crumbs": [
      "core"
    ]
  }
]